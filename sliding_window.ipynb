{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Configuration\n",
    "MODEL_PATH = 'models/resnext101-32x8d-sentinel2-8band/best_model_ce_tv_d13_m07_y2025_h16_m56_s23.pth'\n",
    "NUM_CLASSES = 11\n",
    "NUM_CHANNELS = 8\n",
    "BATCH_SIZE = 32\n",
    "ENCODER_NAME = \"resnext101_32x8d\"\n",
    "ENCODER_WEIGHTS = \"imagenet\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "13b91d2eb59e5c1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "IMG_PATH = \"data/Sentinel2_Annual_Composite_2025-0000189440-0000246272_8band.tif\"\n",
    "CROP_PATH = \"data/sentinel2_4864_top_left.tif\"\n",
    "\n",
    "with rasterio.open(IMG_PATH) as src:\n",
    "    H, W = src.height, src.width\n",
    "    win = Window(0, 0, 4864, 4864)\n",
    "    kwargs = src.meta.copy()\n",
    "    kwargs.update({'height': 4864, 'width': 4864, 'transform': rasterio.windows.transform(win, src.transform)})\n",
    "    with rasterio.open(CROP_PATH, 'w', **kwargs) as dst:\n",
    "        for i in range(1, src.count + 1):\n",
    "            dst.write(src.read(i, window=win), i)\n",
    "print('Cutout saved to:', CROP_PATH)"
   ],
   "id": "856c70d492e449cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Model setup\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=ENCODER_NAME,\n",
    "    encoder_weights=ENCODER_WEIGHTS,\n",
    "    in_channels=NUM_CHANNELS,\n",
    "    classes=NUM_CLASSES,\n",
    "    activation=None\n",
    ").to(DEVICE)\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "print(\"Model loaded successfully\")"
   ],
   "id": "e1541ce0e88d6d2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class FillInvalid:\n",
    "    def __init__(self, global_means, last_k=2):\n",
    "        self.global_means = global_means\n",
    "        self.last_k = last_k\n",
    "\n",
    "    def __call__(self, image):\n",
    "        img = torch.as_tensor(image).float()\n",
    "        invalid = ~torch.isfinite(img)\n",
    "        C = img.shape[0]\n",
    "\n",
    "        for c in range(C):\n",
    "            mask_c = invalid[c]\n",
    "            if not mask_c.any():\n",
    "                continue\n",
    "\n",
    "            if c >= C - self.last_k:\n",
    "                med = torch.nanmedian(img[c])\n",
    "                img[c][mask_c] = med\n",
    "            else:\n",
    "                img[c][mask_c] = self.global_means[c]\n",
    "\n",
    "        return img\n",
    "\n",
    "GLOBAL_MEANS = [0.03402944654226303, 0.04915359988808632, 0.056084536015987396,\n",
    "                0.1244724690914154, 0.12229487299919128, 0.09260836988687515,\n",
    "                0.17983973026275635, -0.011018575169146061]\n",
    "fill_invalid = FillInvalid(GLOBAL_MEANS)\n",
    "\n",
    "# Image normalization\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "normalize = T.Normalize(mean=imagenet_mean, std=imagenet_std)"
   ],
   "id": "eb4c11d054206bf4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class SlidingWindowDataset(Dataset):\n",
    "    def __init__(self, img_path, fill_invalid, window_size=256, stride=128):\n",
    "        self.img_path = img_path\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.fill_invalid = fill_invalid\n",
    "        with rasterio.open(img_path) as src:\n",
    "            self.H, self.W = src.height, src.width\n",
    "        self.window_coords = [\n",
    "            (y, x)\n",
    "            for y in range(0, self.H - window_size + 1, stride)\n",
    "            for x in range(0, self.W - window_size + 1, stride)\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.window_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        y, x = self.window_coords[idx]\n",
    "        with rasterio.open(self.img_path) as src:\n",
    "            patch = src.read(window=Window(x, y, self.window_size, self.window_size)).astype(np.float32)\n",
    "        tensor = torch.from_numpy(patch)   # shape: (8, H, W)\n",
    "        tensor[:3] = normalize(tensor[:3]) # Normalize first 3 channels\n",
    "        tensor = self.fill_invalid(tensor) # Fill invalids (on tensor)\n",
    "        return tensor, y, x"
   ],
   "id": "30472993b1670cbd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def batched_sliding_window_inference(\n",
    "    IMG_PATH,\n",
    "    OUT_PATH,\n",
    "    model,\n",
    "    fill_invalid,\n",
    "    NUM_CLASSES,\n",
    "    DEVICE,\n",
    "    window_size=256,\n",
    "    stride=128,\n",
    "    batch_size=16,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Sliding window inference using DataLoader batching (this implementation should match the test pipeline).\n",
    "    \"\"\"\n",
    "    # Prepare dataset and loader\n",
    "    dataset = SlidingWindowDataset(IMG_PATH, fill_invalid, window_size, stride)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    with rasterio.open(IMG_PATH) as src:\n",
    "        H, W = src.height, src.width\n",
    "        meta = src.meta.copy()\n",
    "        meta.update({\"count\": 1, \"dtype\": 'uint8', \"nodata\": 0})\n",
    "\n",
    "    prob_accumulator = np.zeros((NUM_CLASSES, H, W), dtype=np.float32)\n",
    "    count_mask = np.zeros((H, W), dtype=np.float32)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, ys, xs in tqdm(loader, total=len(loader), disable=not verbose, desc=\"Sliding Window\"):\n",
    "            batch = batch.to(DEVICE)  # shape: (B, 8, window, window)\n",
    "            logits = model(batch)  # shape: (B, NUM_CLASSES, H, W)\n",
    "            probs = torch.softmax(logits, dim=1).cpu().numpy()  # shape: (B, C, H, W)\n",
    "\n",
    "            for i in range(batch.shape[0]):\n",
    "                y, x = int(ys[i]), int(xs[i])\n",
    "                prob_accumulator[:, y:y+window_size, x:x+window_size] += probs[i]\n",
    "                count_mask[y:y+window_size, x:x+window_size] += 1\n",
    "\n",
    "    # Normalize accumulated probabilities and compute final mask\n",
    "    count_mask[count_mask == 0] = 1  # avoid division by zero\n",
    "    final_probs = prob_accumulator / count_mask[None, :, :]\n",
    "    final_mask = np.argmax(final_probs, axis=0).astype(np.uint8)\n",
    "\n",
    "    with rasterio.open(OUT_PATH, 'w', **meta) as dst:\n",
    "        dst.write(final_mask, 1)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Saved sliding window prediction to {OUT_PATH}\")\n",
    "\n",
    "    return final_mask"
   ],
   "id": "41360f76c581a4f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "# Set parameters\n",
    "STRIDE=16\n",
    "IMG_PATH = \"data/sentinel2_4864_top_left.tif\"\n",
    "os.makedirs('predictions', exist_ok=True)\n",
    "OUT_PATH = f\"predictions/prediction_mask_{STRIDE}.tif\"\n",
    "NUM_CLASSES = 11\n",
    "DEVICE = DEVICE     # \"cuda\" or \"cpu\"\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "\n",
    "mask = batched_sliding_window_inference(\n",
    "    IMG_PATH,\n",
    "    OUT_PATH,\n",
    "    model,\n",
    "    fill_invalid,\n",
    "    NUM_CLASSES,\n",
    "    DEVICE,\n",
    "    window_size=256,\n",
    "    stride=STRIDE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ],
   "id": "70d917ccadd64a79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "PALETTE = np.array([\n",
    "    [0, 0, 0, 0],  # Transparent background\n",
    "    [1, 0, 0, 0.7],  # Red\n",
    "    [0, 1, 0, 0.7],  # Green\n",
    "    [0, 0, 1, 0.7],  # Blue\n",
    "    [1, 1, 0, 0.7],  # Yellow\n",
    "    [1, 0, 1, 0.7],  # Magenta\n",
    "    [0, 1, 1, 0.7],  # Cyan\n",
    "    [1, 0.5, 0, 0.7],  # Orange\n",
    "    [0.5, 0, 1, 0.7],  # Purple\n",
    "    [0, 0.5, 0.5, 0.7],  # Teal\n",
    "    [0.5, 0.5, 0, 0.7]  # Olive\n",
    "])"
   ],
   "id": "409876bff50925bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_colored_mask(pred_mask_path, output_path, palette):\n",
    "    with rasterio.open(pred_mask_path) as src:\n",
    "        mask = src.read(1)\n",
    "        profile = src.profile.copy()\n",
    "\n",
    "    if palette.max() <= 1.01:\n",
    "        color_mask = (palette[mask] * 255).astype(np.uint8)\n",
    "    else:\n",
    "        color_mask = palette[mask].astype(np.uint8)\n",
    "\n",
    "    profile.update({'count': 3, 'dtype': 'uint8'})\n",
    "\n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        for i in range(3):\n",
    "            dst.write(color_mask[:, :, i], i + 1)\n",
    "\n",
    "    print(f\"Colored mask saved to: {output_path}\")\n",
    "\n",
    "\n",
    "def save_overlay_png(img_path, mask_path, palette, out_path=\"overlay.png\", alpha=0.9, dpi=300):\n",
    "    with rasterio.open(img_path) as src:\n",
    "        rgb = np.stack([src.read(3), src.read(2), src.read(1)], axis=-1).astype(np.float32)\n",
    "        rgb = (rgb - np.percentile(rgb, 2)) / (np.percentile(rgb, 98) - np.percentile(rgb, 2) + 1e-8)\n",
    "        rgb = np.clip(rgb, 0, 1)\n",
    "\n",
    "    with rasterio.open(mask_path) as src:\n",
    "        mask = src.read(1)\n",
    "\n",
    "    color_mask = palette[mask]\n",
    "    overlay = rgb.copy()\n",
    "    non_bg = mask != 0\n",
    "\n",
    "    for c in range(3):\n",
    "        overlay[..., c][non_bg] = (\n",
    "            (1 - alpha) * rgb[..., c][non_bg] + alpha * color_mask[..., c][non_bg]\n",
    "        )\n",
    "\n",
    "    overlay = np.clip(overlay, 0, 1)\n",
    "    h, w = overlay.shape[:2]\n",
    "    figsize = (w / dpi, h / dpi)\n",
    "\n",
    "    plt.figure(figsize=figsize, dpi=dpi)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(overlay)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "    plt.savefig(out_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    print(f\"Overlay saved to: {out_path}\")\n"
   ],
   "id": "fd6c99e1c53450e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "STRIDE=16\n",
    "PRED_PATH = f\"predictions/prediction_mask_{STRIDE}.tif\"\n",
    "IMG_PATH = \"data/sentinel2_4864_top_left.tif\"\n",
    "MASK_RGB_PATH = f\"predictions/colored_mask_{STRIDE}.tif\"\n",
    "OVERLAY_PNG_PATH = f\"predictions/overlay_visualization_{STRIDE}.png\"\n",
    "\n",
    "save_colored_mask(PRED_PATH, MASK_RGB_PATH, PALETTE)\n",
    "save_overlay_png(IMG_PATH, PRED_PATH, PALETTE, out_path=OVERLAY_PNG_PATH)"
   ],
   "id": "77eaea5a0ca10d2f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
